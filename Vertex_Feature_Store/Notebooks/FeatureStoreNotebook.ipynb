{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzwir9EaTeKT"
   },
   "source": [
    "Terms of Service:\n",
    "\n",
    "This is a [Preview](https://cloud.google.com/products#section-22) release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEaM1hYF6ryZ"
   },
   "source": [
    "This colab demonstrates how to use the Experimental release of the AI Platform\n",
    "Feature Store. This release delivers a small subset of the core functionality of\n",
    "the Feature Store. In particular it enables:\n",
    "\n",
    "1.  Batch ingestion of feature values,\n",
    "2.  Batch serving of feature values (for model training), and\n",
    "3.  Online serving of feature values (for models deployed for online\n",
    "    prediction).\n",
    "\n",
    "This colab assumes that the reader has overall familiarity with Google Cloud AI\n",
    "Platform's planned Feature Store. Please contact\n",
    "caip-featurestore-feedback@google.com if you want access to slides providing an\n",
    "overview.\n",
    "\n",
    "Note that there is a *Troubleshooting* section at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDyYuuHzaen3"
   },
   "source": [
    "# Terminology\n",
    "\n",
    "Here's a quick primer of terminology used in this colab and in the\n",
    "[Feature Store API Documentation](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference).\n",
    "\n",
    "## Feature Store Data Model\n",
    "\n",
    "```\n",
    "Featurestore -> EntityType -> Feature\n",
    "```\n",
    "\n",
    "### Featurestore\n",
    "\n",
    "A featurestore is an instance of Feature Store. It contains all the resources\n",
    "(storage, compute, etc) to support the functionality. Its API resource name is\n",
    "Featurestore.\n",
    "\n",
    "### Entity Type\n",
    "\n",
    "An entity type defines a collection of semantically-related features. For\n",
    "example, in an application, `user` might be an entity type. A specific user (like `user_foo`) is an instance of the entity type and is an entity. Its API resource name is EntityType.\n",
    "\n",
    "### Feature\n",
    "\n",
    "A feature defines a measurable property of an entity type. For example, `user`\n",
    "is an entity type, `user_foo` is an entity, `age` is a feature of entity type\n",
    "`user`, whereas `25` is a feature value. Types of feature values can range from\n",
    "primitives, to strings, to arrays. A complete list of feature value types\n",
    "supported by Feature Store can be found\n",
    "[here](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference/rpc/google.cloud.aiplatform.v1beta1#valuetype).\n",
    "Its API resource name is Feature.\n",
    "\n",
    "## Important terms\n",
    "\n",
    "### Entity\n",
    "\n",
    "A Featurestore is a three-dimensional store: Each Feature value is indexed by an\n",
    "entity ID, Feature ID, and feature generation timestamp.\n",
    "\n",
    "An entity is a collection of Feature values materialized in the Featurestore;\n",
    "more specifically, it is an instance of a defined EntityType. Thus, an entity ID\n",
    "refers to a physical location in the Featurestore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j68Z_of7Xjli"
   },
   "source": [
    "# Prerequisite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9ql-kBcrk5i"
   },
   "source": [
    "**Note:** This colab is tested on\n",
    "[AI Platform Notebooks](https://cloud.google.com/ai-platform-notebooks). Please\n",
    "[create a new notebook instance](https://cloud.google.com/ai-platform/notebooks/docs/create-new)\n",
    "with \"Python 3\" and upload this colab to the notebook instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVs4TVs96l5N"
   },
   "source": [
    "## Set up a Google Cloud project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wrNRJ8p6wre"
   },
   "source": [
    "Please fill out the\n",
    "[Feature Store EAP Registration](https://docs.google.com/forms/d/e/1FAIpQLSd8aocomwk9nV_S3iEvOto4PGxjprUbG223_F1NlPl9-NPUlA/viewform)\n",
    "to allowlist your project and get access to the\n",
    "[Feature Store API documentation](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference).\n",
    "After that, enable the **\"Cloud AI Platform API\"**:\n",
    "\n",
    "```\n",
    "gcloud services enable aiplatform.googleapis.com --project ${your-project-id}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sIyd_aTbX19"
   },
   "source": [
    "## Set up credentials\n",
    "\n",
    "You can only use the private Feature Store SDK in the allowlisted project, with\n",
    "credentials that can access the project. To obtain credentials in the notebook,\n",
    "open a new terminal session (File > New > Terminal). In the terminal, run\n",
    "`gcloud auth login` and follow the instructions to authenticate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bofmg3VXjlk"
   },
   "source": [
    "## Install Feature Store Python SDK\n",
    "\n",
    "> **Note**: If you have installed a previous release of the\n",
    "> google-cloud-aiplatform SDK, you should uninstall it and install the SDK\n",
    "> accompanying this release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nh9lY_YdvVc9"
   },
   "outputs": [],
   "source": [
    "# Uninstall previous version of google-cloud-aiplatform SDK\n",
    "!pip uninstall google-cloud-aiplatform -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oL295lk7Xjll"
   },
   "outputs": [],
   "source": [
    "!gsutil cp gs://cloud-aiplatform-featurestore/sdk/v1beta1/210413/aiplatform-v1beta1-py.tar.gz ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVAGtUZHXjlp"
   },
   "outputs": [],
   "source": [
    "!pip install aiplatform-v1beta1-py.tar.gz\n",
    "!rm aiplatform-v1beta1-py.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIFE1JxQy21U"
   },
   "source": [
    "Now, **restart the kernel** and verify the SDK installation by `pip freeze |\n",
    "grep aiplatform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiplatform-pipelines-client @ file:///home/jupyter/aiplatform_pipelines_client-0.1.0.caip20210415-py3-none-any.whl\n",
      "google-cloud-aiplatform @ file:///home/jupyter/aiplatform-v1beta1-py.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZdyyK-xXjlx"
   },
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "isNzmylQXjly"
   },
   "outputs": [],
   "source": [
    "# Set up project, location, featurestore ID and endpoints\n",
    "PROJECT_ID = \"kubeflow-on-gcp-123\"  #@param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  #@param {type:\"string\"}\n",
    "API_ENDPOINT = \"us-central1-aiplatform.googleapis.com\"  #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kr6pec_YXjl0"
   },
   "outputs": [],
   "source": [
    "from google.api_core import operations_v1\n",
    "from google.cloud.aiplatform_v1beta1 import FeaturestoreOnlineServingServiceClient\n",
    "from google.cloud.aiplatform_v1beta1 import FeaturestoreServiceClient\n",
    "from google.cloud.aiplatform_v1beta1.types import featurestore_online_service as featurestore_online_service_pb2\n",
    "from google.cloud.aiplatform_v1beta1.types import entity_type as entity_type_pb2\n",
    "from google.cloud.aiplatform_v1beta1.types import feature as feature_pb2\n",
    "from google.cloud.aiplatform_v1beta1.types import feature_selector as feature_selector_pb2\n",
    "from google.cloud.aiplatform_v1beta1.types import featurestore as featurestore_pb2\n",
    "from google.cloud.aiplatform_v1beta1.types import featurestore_service as featurestore_service_pb2\n",
    "from google.cloud.aiplatform_v1beta1.types import io as io_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GrmV-FE6Xjl2"
   },
   "outputs": [],
   "source": [
    "# Create admin_client for CRUD and data_client for reading feature values.\n",
    "admin_client = FeaturestoreServiceClient(\n",
    "    client_options={\"api_endpoint\": API_ENDPOINT})\n",
    "data_client = FeaturestoreOnlineServingServiceClient(\n",
    "    client_options={\"api_endpoint\": API_ENDPOINT})\n",
    "\n",
    "# Represents featurestore resource path.\n",
    "BASE_RESOURCE_PATH = admin_client.common_location_path(PROJECT_ID, LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7fiPV0HGXjl5"
   },
   "outputs": [],
   "source": [
    "# Create operation client to poll LRO status.\n",
    "lro_client = operations_v1.OperationsClient(admin_client.transport.grpc_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMAxjJuXXjl7"
   },
   "source": [
    "# Featurestore Admin API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vM8HRLgnXjl7"
   },
   "source": [
    "An administrator can create/manage a featurestore using the\n",
    "[Feature Store Admin API](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference/rpc/google.cloud.aiplatform.v1beta1#featurestoreservice).\n",
    "The administrator can configure some of the featurestore's underlying resources, such as the number of Bigtable nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlwg_HV5Xjl7"
   },
   "source": [
    "## Create featurestore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NNGq6-Cc5nS"
   },
   "source": [
    "The method to create a featurestore returns a\n",
    "[long-running operation](https://google.aip.dev/151) (LRO). An LRO starts an asynchronous job. LROs are returned for other API\n",
    "methods too, such as updating or deleting a featurestore. Calling\n",
    "`create_fs_lro.result()` waits for the LRO to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FscHZa0DXjmC"
   },
   "outputs": [],
   "source": [
    "FEATURESTORE_ID = \"featurestore_demo\"\n",
    "create_lro = admin_client.create_featurestore(\n",
    "    featurestore_service_pb2.CreateFeaturestoreRequest(\n",
    "        parent=BASE_RESOURCE_PATH,\n",
    "        featurestore_id=FEATURESTORE_ID,\n",
    "        featurestore=featurestore_pb2.Featurestore(\n",
    "            display_name=\"My demo featurestore\",\n",
    "            online_serving_config=featurestore_pb2.Featurestore\n",
    "            .OnlineServingConfig(fixed_node_count=3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "57V8eVcB5VFZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wait for LRO to finish and get the LRO result.\n",
    "print(create_lro.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zd73DzNwXjmM"
   },
   "source": [
    "You can use [GetFeaturestore](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference/rpc/google.cloud.aiplatform.v1beta1#google.cloud.aiplatform.v1beta1.FeaturestoreService.GetFeaturestore) or [ListFeaturestores](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference/rpc/google.cloud.aiplatform.v1beta1#google.cloud.aiplatform.v1beta1.FeaturestoreService.ListFeaturestores) to check if the featurestore was successfully created. The following example gets the details of the featurestore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eKhD4q8rXjmM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo\"\n",
       "create_time {\n",
       "  seconds: 1629225762\n",
       "  nanos: 770855000\n",
       "}\n",
       "update_time {\n",
       "  seconds: 1629225762\n",
       "  nanos: 856510000\n",
       "}\n",
       "etag: \"AMEw9yNeT8OElvbCjA_0ZiZWHTrwbzp1vX-xxOzY18Ufsq9V5y0NSZZODPJF-ivbQ_c1\"\n",
       "online_serving_config {\n",
       "  fixed_node_count: 3\n",
       "}\n",
       "state: STABLE"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admin_client.get_featurestore(name = admin_client.featurestore_path(PROJECT_ID, LOCATION, FEATURESTORE_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoZGa1BLXjmS"
   },
   "source": [
    "# Feature Management API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da5dWiwYXjmT"
   },
   "source": [
    "The\n",
    "[Feature Management API](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference/rpc/google.cloud.aiplatform.v1beta1#featurestoreservice)\n",
    "allows you to make CRUD calls for entity types and features. You must create the relevant entity types and features before you run batch ingestion\n",
    "to import feature values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpmJq75zXjmT"
   },
   "source": [
    "## Create entity type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "s9eZ7aJLXjmT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/bikes\"\n",
      "etag: \"AMEw9yPss-TPI1qvq3XX9rozSpjhvipj952PWddpO0UBI5G3fxMy\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entity_type_lro = admin_client.create_entity_type(\n",
    "    featurestore_service_pb2.CreateEntityTypeRequest(\n",
    "        parent=admin_client.featurestore_path(PROJECT_ID, LOCATION, FEATURESTORE_ID),\n",
    "        entity_type_id=\"bikes\", \n",
    "        entity_type=entity_type_pb2.EntityType(description=\"Bike features\")))\n",
    "\n",
    "# Similarly, wait for EntityType creation operation.\n",
    "print(entity_type_lro.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iL1HGum_Xjmf"
   },
   "source": [
    "## Create features\n",
    "\n",
    "Next, register 3 features (`duration_minutes`, `subscriber_type` and `station_array` of type `INT64`, `STRING` and `INT64_ARRAY` respectively) by using the [BatchCreateFeatures](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference/rpc/google.cloud.aiplatform.v1beta1#google.cloud.aiplatform.v1beta1.FeaturestoreService.BatchCreateFeatures) method. You can also use the [CreateFeature](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference/rpc/google.cloud.aiplatform.v1beta1#google.cloud.aiplatform.v1beta1.FeaturestoreService.CreateFeature) method to add one feature at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZJD7-6GFqc1z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/bikes/features/duration_minutes\"\n",
       "  etag: \"AMEw9yOfztkSE3fcAS88dPSxUxIBtZRVMvZKGUYMh0CQR3ZmHFuy\"\n",
       "}\n",
       "features {\n",
       "  name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/bikes/features/subscriber_type\"\n",
       "  etag: \"AMEw9yOn6mTqkXQ1afm-X5ZzNFz3L7_qeD5z1jGCsBGJE8yELjI0\"\n",
       "}\n",
       "features {\n",
       "  name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/bikes/features/station_array\"\n",
       "  etag: \"AMEw9yN2mbbGr4QhpaeA5jzyng3OvGYBp4SwIFRuVpP97t8adTA2\"\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admin_client.batch_create_features(\n",
    "    parent=admin_client.entity_type_path(PROJECT_ID, LOCATION, FEATURESTORE_ID, \"bikes\"),\n",
    "    requests=[\n",
    "        featurestore_service_pb2.CreateFeatureRequest(\n",
    "            feature=feature_pb2.Feature(\n",
    "                value_type=feature_pb2.Feature.ValueType.INT64,\n",
    "                description=\"Bike duration minutes\"),\n",
    "            feature_id=\"duration_minutes\"),\n",
    "        featurestore_service_pb2.CreateFeatureRequest(\n",
    "            feature=feature_pb2.Feature(\n",
    "                value_type=feature_pb2.Feature.ValueType.STRING,\n",
    "                description=\"Subscriber type\"),\n",
    "            feature_id=\"subscriber_type\"),\n",
    "        featurestore_service_pb2.CreateFeatureRequest(\n",
    "            feature=feature_pb2.Feature(\n",
    "                value_type=feature_pb2.Feature.ValueType.INT64_ARRAY,\n",
    "                description=\"Station location array\"),\n",
    "            feature_id=\"station_array\")\n",
    "    ]).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEe0QRF_Xjms"
   },
   "source": [
    "Create the `station` entity type and its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xwhTCPIoXjmu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/stations\"\n",
      "etag: \"AMEw9yPC-vJLDzF-uUkfwATcgnCd_uOT-MF5Kg4KnRFK3VPr5QH6\"\n",
      "\n",
      "features {\n",
      "  name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/stations/features/latitude\"\n",
      "  etag: \"AMEw9yOzJNMYVAFMts2vKC8HBSY9wEebkGl09K9BFkr4lN3J-eCX\"\n",
      "}\n",
      "features {\n",
      "  name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/stations/features/longitude\"\n",
      "  etag: \"AMEw9yNn6iOmWGwvElPFGr--7LcpHWsZdUmE-b58VZ0sZKjoHIOs\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    admin_client.create_entity_type(\n",
    "        featurestore_service_pb2.CreateEntityTypeRequest(\n",
    "            parent=admin_client.featurestore_path(PROJECT_ID, LOCATION,\n",
    "                                                  FEATURESTORE_ID),\n",
    "            entity_type_id=\"stations\",\n",
    "            entity_type=entity_type_pb2.EntityType(\n",
    "                description=\"Station features\"))).result())\n",
    "\n",
    "print(\n",
    "    admin_client.batch_create_features(\n",
    "        parent=admin_client.entity_type_path(PROJECT_ID, LOCATION,\n",
    "                                             FEATURESTORE_ID, \"stations\"),\n",
    "        requests=[\n",
    "            featurestore_service_pb2.CreateFeatureRequest(\n",
    "                feature=feature_pb2.Feature(\n",
    "                    value_type=feature_pb2.Feature.ValueType.DOUBLE,\n",
    "                    description=\"Station latitude\"),\n",
    "                feature_id=\"latitude\"),\n",
    "            featurestore_service_pb2.CreateFeatureRequest(\n",
    "                feature=feature_pb2.Feature(\n",
    "                    value_type=feature_pb2.Feature.ValueType.DOUBLE,\n",
    "                    description=\"Station longitude\"),\n",
    "                feature_id=\"longitude\")\n",
    "        ]).result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUVOzrAb1AFX"
   },
   "source": [
    "## Search features\n",
    "\n",
    "While the [ListFeatures](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference/rpc/google.cloud.aiplatform.v1beta1#google.cloud.aiplatform.v1beta1.FeaturestoreService.ListFeatures) method allows you to easily view all features of a single\n",
    "entity type, the [SearchFeatures](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference/rpc/google.cloud.aiplatform.v1beta1#google.cloud.aiplatform.v1beta1.FeaturestoreService.SearchFeatures) method searches across all featurestores\n",
    "and entity types in a given location (such as `us-central1`). This can help you discover features that were created by someone else.\n",
    "\n",
    "You can query based on feature properties including feature ID, entity type ID,\n",
    "and feature description. You can also limit results by filtering on a specific\n",
    "featurestore, feature value type, and/or labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Hs_7T_hs17ew"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/bikes/features/duration_minutes\"\n",
       " description: \"Bike duration minutes\"\n",
       " create_time {\n",
       "   seconds: 1629225887\n",
       "   nanos: 584465000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1629225887\n",
       "   nanos: 584465000\n",
       " },\n",
       " name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/bikes/features/station_array\"\n",
       " description: \"Station location array\"\n",
       " create_time {\n",
       "   seconds: 1629225887\n",
       "   nanos: 588310000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1629225887\n",
       "   nanos: 588310000\n",
       " },\n",
       " name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/bikes/features/subscriber_type\"\n",
       " description: \"Subscriber type\"\n",
       " create_time {\n",
       "   seconds: 1629225887\n",
       "   nanos: 586231000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1629225887\n",
       "   nanos: 586231000\n",
       " },\n",
       " name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/stations/features/latitude\"\n",
       " description: \"Station latitude\"\n",
       " create_time {\n",
       "   seconds: 1629225963\n",
       "   nanos: 133388000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1629225963\n",
       "   nanos: 133388000\n",
       " },\n",
       " name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/stations/features/longitude\"\n",
       " description: \"Station longitude\"\n",
       " create_time {\n",
       "   seconds: 1629225963\n",
       "   nanos: 135026000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1629225963\n",
       "   nanos: 135026000\n",
       " }]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for all features across all featurestores.\n",
    "list(admin_client.search_features(location=BASE_RESOURCE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmB_QXCy5RBM"
   },
   "source": [
    "Now, narrow down the search to features that are of type `DOUBLE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RcoNHRCTAmBS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/stations/features/latitude\"\n",
       " description: \"Station latitude\"\n",
       " create_time {\n",
       "   seconds: 1629225963\n",
       "   nanos: 133388000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1629225963\n",
       "   nanos: 133388000\n",
       " },\n",
       " name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/stations/features/longitude\"\n",
       " description: \"Station longitude\"\n",
       " create_time {\n",
       "   seconds: 1629225963\n",
       "   nanos: 135026000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1629225963\n",
       "   nanos: 135026000\n",
       " }]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for all features with value type `DOUBLE`\n",
    "list(\n",
    "    admin_client.search_features(\n",
    "        featurestore_service_pb2.SearchFeaturesRequest(\n",
    "            location=BASE_RESOURCE_PATH, query=\"value_type=DOUBLE\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSq2DMUY71Pn"
   },
   "source": [
    "Further limit the search results to features with specific keywords in their ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9NsP2BvU3rLO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/stations/features/latitude\"\n",
       " description: \"Station latitude\"\n",
       " create_time {\n",
       "   seconds: 1629225963\n",
       "   nanos: 133388000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1629225963\n",
       "   nanos: 133388000\n",
       " }]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter on feature value type and keywords.\n",
    "list(\n",
    "    admin_client.search_features(\n",
    "        featurestore_service_pb2.SearchFeaturesRequest(\n",
    "            location=BASE_RESOURCE_PATH, query=\"feature_id:latitude AND value_type=DOUBLE\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3n5XdK8Xjmw"
   },
   "source": [
    "# Batch Ingestion (ImportFeatureValues API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rt2t8NWXjmw"
   },
   "source": [
    "Batch ingestion involves importing feature values for existing features into a\n",
    "featurestore. Hence, it uses the custom HTTP verb `importFeatureValues`. You can ingest values for multiple features at once if all features are of the same entity type. \n",
    "\n",
    "Prior to ingestion, you can have feature values saved in various locations like in BigQuery tables or in Cloud Storage files (files that are in standard formats like Avro or CSV). Post-ingestion, feature values can be served in a uniform format from a featurestore. You might use batch serving for model training and online serving for prediction, for example.\n",
    "\n",
    "  > Note: A featurestore and its source data can be in different projects.\n",
    "  > However, you must grant permissions in the source data project to the\n",
    "  > Feature Store service account. For more information, see the\n",
    "  > \"Cross-project IAM permissions\" section.\n",
    "\n",
    "## Ingestion configuration\n",
    "\n",
    "During batch ingestion of feature values, you must specify the following:\n",
    "\n",
    "*   data source format\n",
    "*   data source location\n",
    "*   destination features that the feature values are instances of\n",
    "\n",
    "Each row in the data source corresponds to one entity, and you must specify how\n",
    "the data source columns correspond to entity IDs, feature generation timestamps,\n",
    "and feature values.\n",
    "\n",
    "You will learn how to set these configurations using [`ImportFeatureValuesRequest`](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference/rpc/google.cloud.aiplatform.v1beta1#google.cloud.aiplatform.v1beta1.ImportFeatureValuesRequest) in\n",
    "the code below.\n",
    "\n",
    "You can **import values for up to 100 features of exactly one entity type**\n",
    "for an `importFeatureValues` operation.\n",
    "\n",
    "### Data source layout\n",
    "\n",
    "The data source must adhere to the following layout for a given row:\n",
    "\n",
    "*   (Required) Column for entity IDs: holds the IDs of the specific entities the\n",
    "    ingested feature values are for, must be of type **String**.\n",
    "*   (Required) Columns for feature values: hold the feature values, and each\n",
    "    column must be of a type compatible with the destination feature.\n",
    "*   (Optional) Column for feature generation timestamps: holds the feature\n",
    "    generation timestamps of the ingested feature values. See details in the\n",
    "    \"Timestamps for ingested feature values\" section. If provided, timestamps\n",
    "    must follow the corresponding requirements, depending on the data source\n",
    "    format:\n",
    "    *   BigQuery table: must be a **TIMESTAMP column**.\n",
    "    *   Avro: must be of **type long and logical type timestamp-micros**.\n",
    "    *   CSV: must be in the **RFC 3339 format**.\n",
    "\n",
    "**Example data source**\n",
    "\n",
    "Here is a schema for Avro data. For a given row, `bike_id` is the column name for the entity ID, and `start_time` is the column name for the feature generation timestamp. The remaining fields (`subscriber_type`, `duration_minutes`, and `station_array`) are column names for feature values.\n",
    "\n",
    "**Avro schema**\n",
    "\n",
    "```\n",
    "{\n",
    "  \"type\":\"record\",\n",
    "  \"name\":\"Root\",\n",
    "  \"fields\":[\n",
    "    {\n",
    "      \"name\":\"bike_id\",\n",
    "      \"type\":[\"null\",\"string\"]},\n",
    "    {\n",
    "      \"name\":\"subscriber_type\",\n",
    "      \"type\":[\"null\",\"string\"]},\n",
    "    {\n",
    "      \"name\":\"start_time\",\n",
    "      \"type\":[\"null\",{\"type\":\"long\",\"logicalType\":\"timestamp-micros\"}]},\n",
    "    {\n",
    "      \"name\":\"duration_minutes\",\n",
    "      \"type\":[\"null\",\"long\"]},\n",
    "    {\n",
    "      \"name\":\"station_array\",\n",
    "      \"type\":{\"type\":\"array\",\"items\":\"long\"}\n",
    "      }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### Timestamps for ingested feature values\n",
    "\n",
    "Batch ingestion expects user-provided timestamps for the ingested feature\n",
    "values. There are two ways to specify timestamps in the [`ImportFeatureValuesRequest`](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference/rpc/google.cloud.aiplatform.v1beta1#google.cloud.aiplatform.v1beta1.ImportFeatureValuesRequest):\n",
    "\n",
    "1.  If the timestamp for all feature values being ingested is the same, you can\n",
    "    specify it just once by using the `feature_time` field as part of the\n",
    "    request.\n",
    "\n",
    "2.  If the timestamps for feature values are different, the timestamps have to\n",
    "    be specified in a column in the data source. In the batch ingestion request,\n",
    "    you can specify the name of that column by using `feature_time_field` field.\n",
    "\n",
    "### Data source location considerations\n",
    "\n",
    "*   If the data source is in Cloud Storage, the data must be in the same\n",
    "    [*region*](https://cloud.google.com/storage/docs/locations#key-concepts)\n",
    "    as the featurestore. For example, a featurestore in\n",
    "    `us-central1` can only ingest data from files in Cloud Storage buckets in\n",
    "    `us-central1`. Ingesting data from dual-region and multi-region buckets is\n",
    "    not supported.\n",
    "\n",
    "*   If the data source is in BigQuery, the data must be in the same\n",
    "    [*region*](https://cloud.google.com/bigquery/docs/locations#key-concepts)\n",
    "    as the featurestore. For example, a\n",
    "    featurestore in `us-central1` can only ingest data from BigQuery tables in\n",
    "    region `us-central1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2FCeECz7VQx"
   },
   "source": [
    "## Import feature values for entities of type bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "RUhm6-yzXjmx"
   },
   "outputs": [],
   "source": [
    "# Specify source data location and its format.\n",
    "import_request = featurestore_service_pb2.ImportFeatureValuesRequest(\n",
    "    entity_type=admin_client.entity_type_path(PROJECT_ID, LOCATION,\n",
    "                                              FEATURESTORE_ID, \"bikes\"),\n",
    "    bigquery_source=io_pb2.BigQuerySource(\n",
    "        input_uri=\"bq://cloud-aiplatform-assets.cloud_aiplatform_featurestore_us_central1.bike_data_2019_10\"\n",
    "    ),\n",
    "    feature_specs=[\n",
    "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(\n",
    "            id=\"subscriber_type\"),\n",
    "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(\n",
    "            id=\"station_array\"),\n",
    "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(\n",
    "            id=\"duration_minutes\"),\n",
    "    ],\n",
    "    entity_id_field=\"bike_id\",\n",
    "    feature_time_field=\"start_time\",\n",
    "    worker_count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICviAzVYN8Yr"
   },
   "source": [
    "> Tips:\n",
    ">\n",
    "> *   Choose the number of workers based on the value of\n",
    ">     [`fixed_node_count`](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference/rpc/google.cloud.aiplatform.v1beta1#featurestore),\n",
    ">     which was set when you provisioned your featurestore. The recommended\n",
    ">     worker:node ratio is 2:1 or 3:1, though you can go higher if the online\n",
    ">     serving load is low. The maximum number of workers is `100`.\n",
    ">\n",
    "> *   The default value for the `entity_id_field` parameter is `entity_id`. If\n",
    ">     your source data already has a column with that same name, you can skip\n",
    ">     setting the `entity_id_field` parameter.\n",
    ">\n",
    "> *   If the source column name is not the same as the target feature ID,\n",
    ">     use the\n",
    ">     [`source_field`](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference/rpc/google.cloud.aiplatform.v1beta1#google.cloud.aiplatform.v1beta1.ImportFeatureValuesRequest.FeatureSpec)\n",
    ">     parameter to specify the source column name. For example:\n",
    ">\n",
    "> ```\n",
    "> featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(\n",
    ">         id=\"subscriber_type\", source_field = 'actual_subscriber'),\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "O5rfbZRYXjm4"
   },
   "outputs": [],
   "source": [
    "# Expect the import to take a few minutes.\n",
    "ingestion_lro = admin_client.import_feature_values(import_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_sDl3ZcrF64T"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imported_entity_count: 8687\n",
       "imported_feature_value_count: 26055"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Polls for the LRO status and prints when the LRO has completed\n",
    "ingestion_lro.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mX_acICy7VQ-"
   },
   "source": [
    "## Import feature values for entities of type stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "eUenNCN77VQ-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imported_entity_count: 96\n",
       "imported_feature_value_count: 192"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_request = featurestore_service_pb2.ImportFeatureValuesRequest(\n",
    "    entity_type=admin_client.entity_type_path(PROJECT_ID, LOCATION,\n",
    "                                              FEATURESTORE_ID, \"stations\"),\n",
    "    bigquery_source=io_pb2.BigQuerySource(\n",
    "        input_uri=\"bq://cloud-aiplatform-assets.cloud_aiplatform_featurestore_us_central1.station_data\"\n",
    "    ),\n",
    "    feature_specs=[\n",
    "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(\n",
    "            id=\"latitude\"),\n",
    "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(\n",
    "            id=\"longitude\"),\n",
    "    ],\n",
    "    entity_id_field=\"station_id\",\n",
    "    feature_time_field=\"update_time\",\n",
    "    worker_count=10)\n",
    "\n",
    "# Expect the import to take a few minutes.\n",
    "admin_client.import_feature_values(import_request).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TdxPYdDXjnA"
   },
   "source": [
    "# Online serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezJIMyU-XjnB"
   },
   "source": [
    "The\n",
    "[Online Serving APIs](https://cloud.google.com/ai-platform-unified/featurestore/docs/reference/rpc/google.cloud.aiplatform.v1beta1#featurestoreonlineservingservice)\n",
    "lets you serve feature values for small batches of entities. Due to its low\n",
    "latency, it is often used to serve feature values to models deployed for online\n",
    "prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foNB0D2aw37c"
   },
   "source": [
    "### Basic read (ReadFeatureValues API)\n",
    "\n",
    "The ReadFeatureValues API is used to read feature values of one entity; hence\n",
    "its custom HTTP verb is `readFeatureValues`. By default, the API will return the\n",
    "latest value of each feature, such as the feature values with the most recent\n",
    "timestamp.\n",
    "\n",
    "To read feature values, specify the entity ID and features to read. The response\n",
    "contains a `header` and an `entity_view`. Each row of data in the `entity_view`\n",
    "contains one feature value, in the same order of features as listed in the response header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3rfWqLrbXjnJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "header {\n",
       "  entity_type: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/bikes\"\n",
       "  feature_descriptors {\n",
       "    id: \"subscriber_type\"\n",
       "  }\n",
       "  feature_descriptors {\n",
       "    id: \"station_array\"\n",
       "  }\n",
       "  feature_descriptors {\n",
       "    id: \"duration_minutes\"\n",
       "  }\n",
       "}\n",
       "entity_view {\n",
       "  entity_id: \"004G\"\n",
       "  data {\n",
       "    value {\n",
       "      string_value: \"Local365\"\n",
       "      metadata {\n",
       "        generate_time {\n",
       "          seconds: 1572277090\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  data {\n",
       "    value {\n",
       "      int64_array_value {\n",
       "        values: 2567\n",
       "        values: 2566\n",
       "      }\n",
       "      metadata {\n",
       "        generate_time {\n",
       "          seconds: 1572277090\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  data {\n",
       "    value {\n",
       "      int64_value: 6\n",
       "      metadata {\n",
       "        generate_time {\n",
       "          seconds: 1572277090\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the features for which to fetch the latest value.\n",
    "feature_selector = feature_selector_pb2.FeatureSelector(\n",
    "    id_matcher=feature_selector_pb2.IdMatcher(\n",
    "        ids=[\"subscriber_type\", \"station_array\", \"duration_minutes\"]))\n",
    "\n",
    "data_client.read_feature_values(\n",
    "    featurestore_online_service_pb2.ReadFeatureValuesRequest(\n",
    "        entity_type=admin_client.entity_type_path(PROJECT_ID, LOCATION,\n",
    "                                                  FEATURESTORE_ID, \"bikes\"),\n",
    "        entity_id=\"004G\",\n",
    "        feature_selector=feature_selector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYk83Zt9xF8m"
   },
   "source": [
    "### Read from multiple entities (StreamingReadFeatureValues API)\n",
    "\n",
    "To read feature values from multiple entities, use the\n",
    "StreamingReadFeatureValues API, which is almost identical to the previous\n",
    "ReadFeatureValues API.\n",
    "\n",
    "Specify the desired entities and feature selectors in one request and then\n",
    "consume from a response stream: Feature Store will first send a `header`-only\n",
    "response, and then send `entity_view`-only responses, one-by-one. Again, each\n",
    "row of data in the `entity_view` contains one feature value, in the same order as listed in the response header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "BIJFcIIHULOd"
   },
   "outputs": [],
   "source": [
    "# Read the same set of features as above, but for multiple entities.\n",
    "response_stream = data_client.streaming_read_feature_values(\n",
    "    featurestore_online_service_pb2.StreamingReadFeatureValuesRequest(\n",
    "        entity_type=admin_client.entity_type_path(PROJECT_ID, LOCATION,\n",
    "                                                  FEATURESTORE_ID, \"bikes\"),\n",
    "        entity_ids=[\"004G\", \"190G\"],\n",
    "        feature_selector=feature_selector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "NFrVLiHyUj2l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header {\n",
      "  entity_type: \"projects/306016756844/locations/us-central1/featurestores/featurestore_demo/entityTypes/bikes\"\n",
      "  feature_descriptors {\n",
      "    id: \"subscriber_type\"\n",
      "  }\n",
      "  feature_descriptors {\n",
      "    id: \"station_array\"\n",
      "  }\n",
      "  feature_descriptors {\n",
      "    id: \"duration_minutes\"\n",
      "  }\n",
      "}\n",
      "\n",
      "entity_view {\n",
      "  entity_id: \"004G\"\n",
      "  data {\n",
      "    value {\n",
      "      string_value: \"Local365\"\n",
      "      metadata {\n",
      "        generate_time {\n",
      "          seconds: 1572277090\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  data {\n",
      "    value {\n",
      "      int64_array_value {\n",
      "        values: 2567\n",
      "        values: 2566\n",
      "      }\n",
      "      metadata {\n",
      "        generate_time {\n",
      "          seconds: 1572277090\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  data {\n",
      "    value {\n",
      "      int64_value: 6\n",
      "      metadata {\n",
      "        generate_time {\n",
      "          seconds: 1572277090\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "entity_view {\n",
      "  entity_id: \"190G\"\n",
      "  data {\n",
      "    value {\n",
      "      string_value: \"ACL 2019 Pass\"\n",
      "      metadata {\n",
      "        generate_time {\n",
      "          seconds: 1572297697\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  data {\n",
      "    value {\n",
      "      int64_array_value {\n",
      "        values: 2711\n",
      "        values: 2501\n",
      "      }\n",
      "      metadata {\n",
      "        generate_time {\n",
      "          seconds: 1572297697\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  data {\n",
      "    value {\n",
      "      int64_value: 14\n",
      "      metadata {\n",
      "        generate_time {\n",
      "          seconds: 1572297697\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate and process response. Note the first one is always the header only.\n",
    "for response in response_stream:\n",
    "  print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpvhPAYxD-Ml"
   },
   "source": [
    "# Batch Serving (BatchReadFeatureValues API)\n",
    "\n",
    "Batch Serving is used to fetch feature values for training a model or for batch\n",
    "prediction. In this user guide we will focus on the scenario of fetching feature\n",
    "values for training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPzAGvqJHh3B"
   },
   "source": [
    "## Fetching feature values for model training\n",
    "\n",
    "Feature Store enables feature sharing i.e. a feature in a featurestore can be\n",
    "used for multiple different use cases. Each use case will have its own training\n",
    "data a.k.a labelled data (i.e. the labels that the model will be trained to\n",
    "predict).\n",
    "\n",
    "Thus, while fetching data from a featurestore to train a model, one has to fetch\n",
    "the feature values that correspond to each label that will be used to train the\n",
    "model.\n",
    "\n",
    "Each label is essentially an observation or measurement, made at a specific\n",
    "point in time, about a specific entity (or entities). For example: Did the user\n",
    "click on the ad, did the user purchase the product, etc. Thus for each label,\n",
    "one has to fetch the feature values for the corresponding entity (or entities),\n",
    "as of the point in time when the label was observed or measured.\n",
    "\n",
    "That is exactly what the BatchReadFeatureValues function does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fldm9htEH2YK"
   },
   "source": [
    "## Inputs and outputs of BatchReadFeatureValues\n",
    "\n",
    "**Inputs**:\n",
    "\n",
    "Users need to provide the following info in the request:\n",
    "\n",
    "*   Features to read (i.e. the features for which values are requested). If an\n",
    "    EntityType were a table, each Feature ID would select a column.\n",
    "*   An input file containing the following information for each training\n",
    "    instance:\n",
    "\n",
    "> *   **Timestamp**: This allows Feature Store to fetch feature values as of the\n",
    ">     point in time when the label was observed/measured.\n",
    "\n",
    "> *   **Entity ID(s)**: The ID(s) of the entity/entities corresponding to the\n",
    ">     labelled instance. You can think of these IDs as the keys that will be\n",
    ">     used to concatenate feature values. If an EntityType were a table, each\n",
    ">     entity ID would select a row.\n",
    "\n",
    "*   Destination URI and format.\n",
    "\n",
    "**Output**:\n",
    "\n",
    "A file, at the user-specified destination URI, containing the requested feature\n",
    "values for each training instance.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "Let's continue with the bike/station dataset and suppose we are given a machine\n",
    "learning task to predict whether a bike is available at a given station. For\n",
    "this model, the training data we need would be a join of some bikes and stations\n",
    "features, whose label may come from ground-truth that describes whether a bike X\n",
    "was available at station Y.\n",
    "\n",
    "To be more specific, the desired training dataset is described in Table 1. Here,\n",
    "we use the `subscriber_type` and `duration_minutes` features from `bikes` and\n",
    "the `latitude` and `longitude` features from `stations`. Our ground-truth\n",
    "observation is described in Table 2. BatchReadFeatureValues API takes Table 2 as\n",
    "input and returns Table 1 for training.\n",
    "\n",
    "<h4 align=\"center\">Table 1. Expected Training Data Generated by Batch Read API</h4>\n",
    "\n",
    "timestamp            | entity_type_bikes | subscriber_type | duration_minutes | entity_type_stations | latitude | longitude | label\n",
    "-------------------- | ----------------- | --------------- | ---------------- | -------------------- | -------- | --------- | -----\n",
    "2019-11-01T00:00:00Z | 004G              | Local365        | 6                | 3841                 | 30.28728 | -97.74495 | True\n",
    "2019-11-15T18:09:43Z | 190G              | ACL 2019 Pass   | 14               | 2567                 | 30.25971 | -97.75346 | True\n",
    "...                  | ...               | ...             | ...              | ...                  | ...      | ...       | ...\n",
    "\n",
    "<h4 align=\"center\">Table 2. Example of Ground-truth Data</h4>\n",
    "\n",
    "bikes | stations | timestamp            | label\n",
    "----- | -------- | -------------------- | -----\n",
    "004G  | 3841     | 2019-11-01T00:00:00Z | True\n",
    "190G  | 2567     | 2019-11-15T18:09:43Z | True\n",
    "...   | ...      | ...                  | ...\n",
    "\n",
    "Next, let's figure out how to call the API and generate such training data using\n",
    "the ground-truth data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAL9Y4VTOLT1"
   },
   "source": [
    "## API Details\n",
    "\n",
    "Step 1. In the project, create a dataset to store output, using the [BigQuery console](https://console.cloud.google.com/bigquery). For the input ground-truth data, use the public data located at ```gs://cloud-aiplatform-featurestore-us-central1/read_entity_instance.csv```. This ground-truth data is used to select entities from each requested entity type along with the features.\n",
    "\n",
    "Step 2. Assemble the query following the steps below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "QOaGi2PrEAwA"
   },
   "outputs": [],
   "source": [
    "# The input file containing the ground-truth data (table 2) is a CSV file in a Cloud Storage bucket.\n",
    "# In this demo, use the following public data, nothing needs to be changed here.\n",
    "INPUT_CSV_FILE = \"gs://cloud-aiplatform-featurestore-us-central1/read_entity_instance.csv\"\n",
    "\n",
    "# Output data set, as created in the step 1.\n",
    "DESTINATION_DATA_SET = \"sink\"  #@param {type:\"string\"}\n",
    "# Output table. Make sure that the table does NOT already exist; the BatchReadFeatureValues API cannot overwrite an existing table\n",
    "DESTINATION_TABLE_NAME = \"demo_output\" #@param {type:\"string\"}\n",
    "\n",
    "DESTINATION_PATTERN = \"bq://{project}.{dataset}.{table}\"\n",
    "DESTINATION_TABLE_URI = DESTINATION_PATTERN.format(project=PROJECT_ID,\n",
    "    dataset=DESTINATION_DATA_SET, table=DESTINATION_TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "7IyoXHY2ECnh"
   },
   "outputs": [],
   "source": [
    "batch_serving_request = featurestore_service_pb2.BatchReadFeatureValuesRequest(\n",
    "    # featurestore info\n",
    "    featurestore=admin_client.featurestore_path(PROJECT_ID, LOCATION,\n",
    "                                                FEATURESTORE_ID),\n",
    "    # Input file specifying the entities to be read\n",
    "    csv_read_instances=io_pb2.CsvSource(\n",
    "        gcs_source=io_pb2.GcsSource(uris=[INPUT_CSV_FILE])),\n",
    "    # Output info\n",
    "    destination=featurestore_service_pb2.FeatureValueDestination(\n",
    "        bigquery_destination=io_pb2.BigQueryDestination(\n",
    "            # output to BigQuery table\n",
    "            output_uri=DESTINATION_TABLE_URI)),\n",
    "    # Select features to read\n",
    "    entity_type_specs=[\n",
    "        featurestore_service_pb2.BatchReadFeatureValuesRequest.EntityTypeSpec(\n",
    "            # read feature values of features subscriber_type and duration_minutes from \"bikes\"\n",
    "            entity_type_id=\"bikes\", \n",
    "            feature_selector=feature_selector_pb2.FeatureSelector(\n",
    "                id_matcher=feature_selector_pb2.IdMatcher(ids=[\n",
    "                    # features, use \"*\" if you want to select all features within this entity type\n",
    "                    \"subscriber_type\",  \"duration_minutes\"\n",
    "                ]))),\n",
    "        featurestore_service_pb2.BatchReadFeatureValuesRequest.EntityTypeSpec(\n",
    "            # read feature values of features latitude and longitude from \"stations\"\n",
    "            entity_type_id=\"stations\",\n",
    "            feature_selector=feature_selector_pb2.FeatureSelector(\n",
    "                id_matcher=feature_selector_pb2.IdMatcher(\n",
    "                    ids=[\"latitude\", \"longitude\"])))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcwXDbi7psbd"
   },
   "source": [
    "Step 3. Send the batch read request and wait for the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "bZO5sRCfEEWn"
   },
   "outputs": [],
   "source": [
    "# Execute the batch read operation\n",
    "serving_lro = admin_client.batch_read_feature_values(batch_serving_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ouMiJqh-EFlh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This long runing operation will poll until the batch read finishes.\n",
    "serving_lro.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RAdjahHQ93J"
   },
   "source": [
    "After the LRO finishes, you should be able to see the result from the [BigQuery console](https://console.cloud.google.com/bigquery), in the table created in Step 2. For more details, see the document [here](https://docs.google.com/document/d/10RMIfHHcQFTf3jmyck00g1YKbvZDBAHjSBbtF4k6Nv0/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQ1vV4EJzQBF"
   },
   "source": [
    "## Cleaning Up\n",
    "Delete the featurestore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "a2WfqhbFzQBF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admin_client.delete_featurestore(\n",
    "    request=featurestore_service_pb2.DeleteFeaturestoreRequest(\n",
    "        name=admin_client.featurestore_path(PROJECT_ID, LOCATION, \"featurestore_demo\"),\n",
    "        force=True)).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QW_DD8gTHFDx"
   },
   "source": [
    "# Cross-project IAM permissions\n",
    "\n",
    "By default, Feature Store has the IAM permissions to access source data in the\n",
    "same project as the featurestore. It is recommended that you keep the default\n",
    "IAM permissions established for your project. However, if the **source data is\n",
    "in a different project from the featurestore**, you must manually grant\n",
    "permission to the Feature Store service account in the source data project.\n",
    "\n",
    "Specify your Google Cloud\n",
    "[project number](https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects)\n",
    "where your featurestore is located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-XgEPdcHHJz"
   },
   "outputs": [],
   "source": [
    "# Specify your project number where the featurestore is located.\n",
    "PROJECT_NUMBER = 0\n",
    "\n",
    "# Specify the project ID where the source data is located.\n",
    "SOURCE_DATA_PROJECT_ID = \"SOURCE-DATA-PROJECT-ID\"\n",
    "FEATURE_STORE_SERVICE_ACCOUNT = \"service-{}@gcp-sa-aiplatform.iam.gserviceaccount.com\".format(PROJECT_NUMBER)\n",
    "\n",
    "# Grant featurestore service account roles/aiplatform.serviceAgent in the source data project.\n",
    "!gcloud projects add-iam-policy-binding {SOURCE_DATA_PROJECT_ID} --member=serviceAccount:{FEATURE_STORE_SERVICE_ACCOUNT} --role=\"roles/aiplatform.serviceAgent\" --condition=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UI7C_LwrKqNk"
   },
   "source": [
    "Use the following command to verify that the service account has been\n",
    "successfully granted the role `roles/aiplatform.serviceAgent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VLnDuyYKHRu"
   },
   "outputs": [],
   "source": [
    "!gcloud projects get-iam-policy {SOURCE_DATA_PROJECT_ID} --flatten=\"bindings[].members\" --format='table(bindings.role)' --filter=\"bindings.members:serviceAccount:{FEATURE_STORE_SERVICE_ACCOUNT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3Au_6jLfJk8"
   },
   "source": [
    "# Troubleshooting\n",
    "\n",
    "*   After installing the Python SDK, you might see an error message containing\n",
    "    \"fail to load proto\".\n",
    "\n",
    "This is due to a mismatch between the protobuf compiler version and the Python\n",
    "protobuf package version. Run the following commands:\n",
    "\n",
    "```bash\n",
    "pip uninstall protobuf python3-protobuf\n",
    "pip install --upgrade pip\n",
    "\n",
    "# find your protobuf compiler's version by running \"protoc --version\" in the terminal\n",
    "pip install --upgrade protobuf==${YOUR_PROTOC_VERSION}\n",
    "```\n",
    "\n",
    "*   If you are unable to access Cloud Storage buckets, run `gcloud auth login`."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FeatureStoreColab210413.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-5.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
