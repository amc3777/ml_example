{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "737094eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install {USER_FLAG} google-cloud-aiplatform --upgrade\n",
    "!pip3 install {USER_FLAG} kfp google-cloud-pipeline-components --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb7d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684e64a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 1.7.0\n",
      "google_cloud_pipeline_components version: 0.1.4\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "!python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8608204c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID:  kubeflow-on-gcp-123\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PROJECT_ID = \"\"\n",
    "\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)\n",
    "\n",
    "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
    "    PROJECT_ID = \"kubeflow-on-gcp-123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1690a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME=\"gs://aiplatform-custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a558d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, ClassificationMetrics, Metrics, component)\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2356df93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/jupyter/.local/bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://aiplatform-custom/pipeline_root/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "REGION=\"us-central1\"\n",
    "\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline_root/\"\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253be82c",
   "metadata": {},
   "source": [
    "#### Custom Python based component for model evaluation\n",
    "##### This function renders evaluation metrics for an AutoML Tabular classification model.\n",
    "##### It retrieves the classification model evaluation generated by the AutoML Tabular training\n",
    "##### process, does some parsing, and uses that info to render the ROC curve and confusion matrix\n",
    "##### for the model. It also uses given metrics threshold information and compares that to the\n",
    "##### evaluation results to determine whether the model is sufficiently accurate to deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66fa0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"gcr.io/deeplearning-platform-release/tf2-cpu.2-3:latest\",\n",
    "    output_component_file=\"tables_eval_component.yaml\",\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"],\n",
    ")\n",
    "def classif_model_eval_metrics(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    api_endpoint: str,\n",
    "    thresholds_dict_str: str,\n",
    "    model: Input[Model], # output of previous step (training)\n",
    "    metrics: Output[Metrics],\n",
    "    metricsc: Output[ClassificationMetrics],\n",
    ") -> NamedTuple(\"Outputs\", [(\"dep_decision\", str)]):  # Return parameter.\n",
    "    \n",
    "    import json\n",
    "    import logging\n",
    "\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    # Fetch model eval info\n",
    "    def get_eval_info(client, model_name):\n",
    "        from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "        response = client.list_model_evaluations(parent=model_name)\n",
    "        metrics_list = []\n",
    "        metrics_string_list = []\n",
    "        for evaluation in response:\n",
    "            print(\"model_evaluation\")\n",
    "            print(\" name:\", evaluation.name)\n",
    "            print(\" metrics_schema_uri:\", evaluation.metrics_schema_uri)\n",
    "            metrics = MessageToDict(evaluation._pb.metrics)\n",
    "            for metric in metrics.keys():\n",
    "                logging.info(\"metric: %s, value: %s\", metric, metrics[metric])\n",
    "            metrics_str = json.dumps(metrics)\n",
    "            metrics_list.append(metrics)\n",
    "            metrics_string_list.append(metrics_str)\n",
    "\n",
    "        return (\n",
    "            evaluation.name,\n",
    "            metrics_list,\n",
    "            metrics_string_list,\n",
    "        )\n",
    "\n",
    "    # Use the given metrics threshold(s) to determine whether the model is \n",
    "    # accurate enough to deploy.\n",
    "    def classification_thresholds_check(metrics_dict, thresholds_dict):\n",
    "        for k, v in thresholds_dict.items():\n",
    "            logging.info(\"k {}, v {}\".format(k, v))\n",
    "            if k in [\"auRoc\", \"auPrc\"]:  # higher is better\n",
    "                if metrics_dict[k] < v:  # if under threshold, don't deploy\n",
    "                    logging.info(\n",
    "                        \"{} < {}; returning False\".format(metrics_dict[k], v)\n",
    "                    )\n",
    "                    return False\n",
    "        logging.info(\"threshold checks passed.\")\n",
    "        return True\n",
    "\n",
    "    def log_metrics(metrics_list, metricsc):\n",
    "        test_confusion_matrix = metrics_list[0][\"confusionMatrix\"]\n",
    "        logging.info(\"rows: %s\", test_confusion_matrix[\"rows\"])\n",
    "\n",
    "        # log the ROC curve\n",
    "        fpr = []\n",
    "        tpr = []\n",
    "        thresholds = []\n",
    "        for item in metrics_list[0][\"confidenceMetrics\"]:\n",
    "            fpr.append(item.get(\"falsePositiveRate\", 0.0))\n",
    "            tpr.append(item.get(\"recall\", 0.0))\n",
    "            thresholds.append(item.get(\"confidenceThreshold\", 0.0))\n",
    "        print(f\"fpr: {fpr}\")\n",
    "        print(f\"tpr: {tpr}\")\n",
    "        print(f\"thresholds: {thresholds}\")\n",
    "        metricsc.log_roc_curve(fpr, tpr, thresholds)\n",
    "\n",
    "        # log the confusion matrix\n",
    "        annotations = []\n",
    "        for item in test_confusion_matrix[\"annotationSpecs\"]:\n",
    "            annotations.append(item[\"displayName\"])\n",
    "        logging.info(\"confusion matrix annotations: %s\", annotations)\n",
    "        metricsc.log_confusion_matrix(\n",
    "            annotations,\n",
    "            test_confusion_matrix[\"rows\"],\n",
    "        )\n",
    "\n",
    "        # log textual metrics info as well\n",
    "        for metric in metrics_list[0].keys():\n",
    "            if metric != \"confidenceMetrics\":\n",
    "                val_string = json.dumps(metrics_list[0][metric])\n",
    "                metrics.log_metric(metric, val_string)\n",
    "        # metrics.metadata[\"model_type\"] = \"AutoML Tabular classification\"\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    aiplatform.init(project=project)\n",
    "    # extract the model resource name from the input Model Artifact\n",
    "    model_resource_path = model.uri.replace(\"aiplatform://v1/\", \"\")\n",
    "    logging.info(\"model path: %s\", model_resource_path)\n",
    "\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    client = aiplatform.gapic.ModelServiceClient(client_options=client_options)\n",
    "    eval_name, metrics_list, metrics_str_list = get_eval_info(\n",
    "        client, model_resource_path\n",
    "    )\n",
    "    logging.info(\"got evaluation name: %s\", eval_name)\n",
    "    logging.info(\"got metrics list: %s\", metrics_list)\n",
    "    log_metrics(metrics_list, metricsc)\n",
    "\n",
    "    thresholds_dict = json.loads(thresholds_dict_str)\n",
    "    deploy = classification_thresholds_check(metrics_list[0], thresholds_dict)\n",
    "    if deploy:\n",
    "        dep_decision = \"true\"\n",
    "    else:\n",
    "        dep_decision = \"false\"\n",
    "    logging.info(\"deployment decision is %s\", dep_decision)\n",
    "\n",
    "    return (dep_decision,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12d2da47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automl-beans1628709384\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "DISPLAY_NAME = 'automl-beans{}'.format(str(int(time.time())))\n",
    "print(DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ee79fd",
   "metadata": {},
   "source": [
    "#### Pipeline definition using Google Cloud pipeline components and custom component for model eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0757707",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name=\"automl-tab-beans-training-v2\",\n",
    "                  pipeline_root=PIPELINE_ROOT)\n",
    "def pipeline(\n",
    "    bq_source: str = \"bq://aju-dev-demos.beans.beans1\",\n",
    "    display_name: str = DISPLAY_NAME,\n",
    "    project: str = PROJECT_ID,\n",
    "    gcp_region: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "    thresholds_dict_str: str = '{\"auRoc\": 0.95}',\n",
    "):\n",
    "    dataset_create_op = gcc_aip.TabularDatasetCreateOp(\n",
    "        project=project, display_name=display_name, bq_source=bq_source\n",
    "    )\n",
    "\n",
    "    training_op = gcc_aip.AutoMLTabularTrainingJobRunOp(\n",
    "        project=project,\n",
    "        display_name=display_name,\n",
    "        optimization_prediction_type=\"classification\",\n",
    "        budget_milli_node_hours=1000,\n",
    "        column_transformations=[\n",
    "            {\"numeric\": {\"column_name\": \"Area\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Perimeter\"}},\n",
    "            {\"numeric\": {\"column_name\": \"MajorAxisLength\"}},\n",
    "            {\"numeric\": {\"column_name\": \"MinorAxisLength\"}},\n",
    "            {\"numeric\": {\"column_name\": \"AspectRation\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Eccentricity\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ConvexArea\"}},\n",
    "            {\"numeric\": {\"column_name\": \"EquivDiameter\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Extent\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Solidity\"}},\n",
    "            {\"numeric\": {\"column_name\": \"roundness\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Compactness\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor1\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor2\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor3\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor4\"}},\n",
    "            {\"categorical\": {\"column_name\": \"Class\"}},\n",
    "        ],\n",
    "        dataset=dataset_create_op.outputs[\"dataset\"],\n",
    "        target_column=\"Class\",\n",
    "    )\n",
    "    model_eval_task = classif_model_eval_metrics(\n",
    "        project,\n",
    "        gcp_region,\n",
    "        api_endpoint,\n",
    "        thresholds_dict_str,\n",
    "        training_op.outputs[\"model\"],\n",
    "    )\n",
    "\n",
    "    with dsl.Condition(\n",
    "        model_eval_task.outputs[\"dep_decision\"] == \"true\",\n",
    "        name=\"deploy_decision\",\n",
    "    ):\n",
    "\n",
    "        deploy_op = gcc_aip.ModelDeployOp(  # noqa: F841\n",
    "            model=training_op.outputs[\"model\"],\n",
    "            project=project,\n",
    "            machine_type=\"n1-standard-4\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2390842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"tab_classif_pipeline.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebcc1d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/kfp/v2/google/client/client.py:175: FutureWarning: AIPlatformClient will be deprecated in v1.9. Please use PipelineJob https://googleapis.dev/python/aiplatform/latest/_modules/google/cloud/aiplatform/pipeline_jobs.html in Vertex SDK. Install the SDK using \"pip install google-cloud-aiplatform\"\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "api_client = AIPlatformClient(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d7db700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/automl-tab-beans-training-v2-20210811210428?project=kubeflow-on-gcp-123\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = api_client.create_run_from_job_spec(\n",
    "    \"tab_classif_pipeline.json\", pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\"project\": PROJECT_ID,\n",
    "                      \"display_name\": DISPLAY_NAME},\n",
    "    enable_caching=True # True by default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d01d1731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.input:bq_source</th>\n",
       "      <th>param.input:api_endpoint</th>\n",
       "      <th>param.input:display_name</th>\n",
       "      <th>param.input:project</th>\n",
       "      <th>param.input:thresholds_dict_str</th>\n",
       "      <th>param.input:gcp_region</th>\n",
       "      <th>metric.confidenceMetrics</th>\n",
       "      <th>metric.confusionMatrix</th>\n",
       "      <th>metric.logLoss</th>\n",
       "      <th>metric.auRoc</th>\n",
       "      <th>metric.auPrc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>automl-tab-beans-training-v2</td>\n",
       "      <td>automl-tab-beans-training-v2-20210811191642</td>\n",
       "      <td>bq://aju-dev-demos.beans.beans1</td>\n",
       "      <td>us-central1-aiplatform.googleapis.com</td>\n",
       "      <td>automl-beans1628709384</td>\n",
       "      <td>kubeflow-on-gcp-123</td>\n",
       "      <td>{\"auRoc\": 0.95}</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>[{'recall': 1.0, 'falsePositiveRate': 1.0, 'co...</td>\n",
       "      <td>{\"rows\": [[124.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0...</td>\n",
       "      <td>0.15068907</td>\n",
       "      <td>0.99700993</td>\n",
       "      <td>0.98708546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>automl-tab-beans-training-v2</td>\n",
       "      <td>automl-tab-beans-training-v2-20210730180825</td>\n",
       "      <td>bq://aju-dev-demos.beans.beans1</td>\n",
       "      <td>us-central1-aiplatform.googleapis.com</td>\n",
       "      <td>automl-beans1627664846</td>\n",
       "      <td>kubeflow-on-gcp-123</td>\n",
       "      <td>{\"auRoc\": 0.95}</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>[{'recall': 1.0, 'falsePositiveRate': 1.0, 'co...</td>\n",
       "      <td>{'rows': [{'row': [123.0, 0.0, 7.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.15121664</td>\n",
       "      <td>0.9969781</td>\n",
       "      <td>0.98694754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pipeline_name                                     run_name  \\\n",
       "0  automl-tab-beans-training-v2  automl-tab-beans-training-v2-20210811191642   \n",
       "1  automl-tab-beans-training-v2  automl-tab-beans-training-v2-20210730180825   \n",
       "\n",
       "             param.input:bq_source               param.input:api_endpoint  \\\n",
       "0  bq://aju-dev-demos.beans.beans1  us-central1-aiplatform.googleapis.com   \n",
       "1  bq://aju-dev-demos.beans.beans1  us-central1-aiplatform.googleapis.com   \n",
       "\n",
       "  param.input:display_name  param.input:project  \\\n",
       "0   automl-beans1628709384  kubeflow-on-gcp-123   \n",
       "1   automl-beans1627664846  kubeflow-on-gcp-123   \n",
       "\n",
       "  param.input:thresholds_dict_str param.input:gcp_region  \\\n",
       "0                 {\"auRoc\": 0.95}            us-central1   \n",
       "1                 {\"auRoc\": 0.95}            us-central1   \n",
       "\n",
       "                            metric.confidenceMetrics  \\\n",
       "0  [{'recall': 1.0, 'falsePositiveRate': 1.0, 'co...   \n",
       "1  [{'recall': 1.0, 'falsePositiveRate': 1.0, 'co...   \n",
       "\n",
       "                              metric.confusionMatrix metric.logLoss  \\\n",
       "0  {\"rows\": [[124.0, 0.0, 6.0, 0.0, 0.0, 1.0, 0.0...     0.15068907   \n",
       "1  {'rows': [{'row': [123.0, 0.0, 7.0, 0.0, 0.0, ...     0.15121664   \n",
       "\n",
       "  metric.auRoc metric.auPrc  \n",
       "0   0.99700993   0.98708546  \n",
       "1    0.9969781   0.98694754  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_df = aiplatform.get_pipeline_df(pipeline=\"automl-tab-beans-training-v2\")\n",
    "small_pipeline_df = pipeline_df.head(2)\n",
    "small_pipeline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f12453",
   "metadata": {},
   "source": [
    "#### Create a scheduled pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25c083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = api_client.create_schedule_from_job_spec(\n",
    "    job_spec_path=\"intro_pipeline_job.json\",\n",
    "    schedule=\"2 * * * *\",\n",
    "    time_zone=\"America/Los_Angeles\",  # change this as necessary\n",
    "    parameter_values={\"text\":\"Cloud Scheduler\", \"emoji_str\": \"100\"},\n",
    "    pipeline_root=PIPELINE_ROOT\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
